name: Compile MLC-LLM for iOS

on:
  workflow_dispatch:

jobs:
  compile-ios:
    runs-on: macos-14
    timeout-minutes: 120
    
    steps:
    - name: Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        
    - name: Install Rust
      uses: dtolnay/rust-toolchain@stable
      
    - name: Install dependencies
      run: |
        pip install numpy decorator attrs typing_extensions psutil scipy tornado
        brew install ninja
        
    - name: Clone MLC-LLM
      run: |
        git clone --recursive https://github.com/mlc-ai/mlc-llm.git
        
    - name: Build MLC-LLM
      run: |
        cd mlc-llm
        mkdir -p build && cd build
        
        TVM_PATH="$(cd ../3rdparty/tvm && pwd)"
        
        cat > config.cmake << EOF
        set(TVM_SOURCE_DIR "$TVM_PATH")
        set(USE_CUDA OFF)
        set(USE_METAL ON)
        set(USE_VULKAN OFF)
        set(USE_OPENCL OFF)
        set(USE_FLASHINFER OFF)
        set(CMAKE_BUILD_TYPE Release)
        EOF
        
        cmake .. \
          -DCMAKE_BUILD_TYPE=Release \
          -DCMAKE_POLICY_VERSION_MINIMUM=3.5 \
          -GNinja
        
        ninja -j$(sysctl -n hw.ncpu)
        
    - name: Verify MLC-LLM installation
      run: |
        cd mlc-llm
        export PYTHONPATH=$(pwd)/python:$(pwd)/3rdparty/tvm/python:$PYTHONPATH
        
        python -c "import tvm; print('TVM OK')"
        python -c "import mlc_llm; print('MLC-LLM OK')"
        python -m mlc_llm --help | head -10
        
    - name: Download Model
      run: |
        pip install huggingface_hub
        huggingface-cli download mlc-ai/Qwen3-4B-q4f16_1-MLC --local-dir ./model
        cat ./model/mlc-chat-config.json
        
    - name: Generate config with small buffers
      run: |
        cd mlc-llm
        export PYTHONPATH=$(pwd)/python:$(pwd)/3rdparty/tvm/python:$PYTHONPATH
        
        mkdir -p ../config
        
        python -m mlc_llm gen_config ../model \
          --quantization q4f16_1 \
          --prefill-chunk-size 128 \
          --context-window-size 4096 \
          --max-batch-size 1 \
          --conv-template qwen2 \
          --output ../config
        
        cat ../config/mlc-chat-config.json
        
    - name: Compile for iOS
      run: |
        cd mlc-llm
        export PYTHONPATH=$(pwd)/python:$(pwd)/3rdparty/tvm/python:$PYTHONPATH
        
        mkdir -p ../output
        
        python -m mlc_llm compile ../config/mlc-chat-config.json \
          --device iphone \
          --output ../output/model-iphone.tar
        
    - name: Extract compiled files
      run: |
        cd output
        tar -xvf model-iphone.tar
        ls -lh *.o
        
    - name: Upload artifacts
      uses: actions/upload-artifact@v4
      with:
        name: ios-compiled-libs
        path: |
          output/*.o
          config/mlc-chat-config.json
        retention-days: 30
