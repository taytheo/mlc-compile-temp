name: Compile MLC-LLM for iOS

on:
  workflow_dispatch:

jobs:
  compile-ios:
    runs-on: macos-14
    timeout-minutes: 180

    defaults:
      run:
        shell: bash -el {0}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Conda
        uses: conda-incubator/setup-miniconda@v3
        with:
          auto-update-conda: true
          python-version: "3.11"
          activate-environment: mlc

      - name: Install MLC-LLM Python package
        run: |
          pip install --pre -U -f https://mlc.ai/wheels mlc-llm-nightly-cpu mlc-ai-nightly-cpu
          pip install huggingface_hub

      - name: Patch MLC-LLM bool type bug
        run: |
          echo "ðŸ”§ MLC-LLM Bool íƒ€ìž… ë²„ê·¸ íŒ¨ì¹˜ ì‹œìž‘ (GitHub Issue #3389)"
          python3 .github/scripts/patch_mlc_bool_bug.py

      - name: Download original HuggingFace model
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          mkdir -p model_weights
          echo "ðŸ“¥ Downloading original Qwen3-4B from HuggingFace..."
          python3 << 'EOF'
          import os
          from huggingface_hub import snapshot_download
          token = os.environ.get('HF_TOKEN')
          snapshot_download(
              repo_id='Qwen/Qwen3-4B',
              local_dir='./model_weights/Qwen3-4B',
              ignore_patterns=['*.bin', '*.safetensors'],
              token=token
          )
          EOF
          echo "=== Downloaded files ==="
          ls -la ./model_weights/Qwen3-4B/

      - name: Generate optimized config for iPhone
        run: |
          echo "âš™ï¸ Generating config with low memory settings..."
          python -m mlc_llm gen_config \
            ./model_weights/Qwen3-4B \
            --quantization q4f16_1 \
            --model-type qwen3 \
            --conv-template qwen2 \
            --prefill-chunk-size 32 \
            --context-window-size 1024 \
            --max-batch-size 1 \
            --output ./model_weights/Qwen3-4B-compiled \
            2>&1 | tee gen_config_log.txt
          echo "=== Generated config ==="
          cat ./model_weights/Qwen3-4B-compiled/mlc-chat-config.json

      - name: Download pre-quantized weights
        run: |
          echo "ðŸ“¥ Downloading pre-quantized weights..."
          python -c "from huggingface_hub import snapshot_download; snapshot_download(repo_id='mlc-ai/Qwen3-4B-q4f16_1-MLC', local_dir='./model_weights/Qwen3-4B-compiled', allow_patterns=['*.bin', 'ndarray-cache.json'])"
          # ìƒˆë¡œ ìƒì„±í•œ config ìœ ì§€
          echo "=== Model directory ==="
          ls -la ./model_weights/Qwen3-4B-compiled/

      - name: Compile for iOS
        run: |
          mkdir -p ./output
          echo "ðŸ”¨ Starting iOS compilation with optimized config..."
          python -m mlc_llm compile \
            ./model_weights/Qwen3-4B-compiled/mlc-chat-config.json \
            --device iphone \
            --output ./output/qwen3_q4f16_1-iphone.tar \
            2>&1 | tee compile_log.txt
          echo "=== Compilation output ==="
          ls -la ./output/

      - name: Extract compiled files
        if: success()
        run: |
          cd output
          if [ -f qwen3_q4f16_1-iphone.tar ]; then
            tar -xvf qwen3_q4f16_1-iphone.tar
            echo "=== Extracted files ==="
            ls -lh
          fi

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: qwen3-4b-ios-compiled-lowmem
          path: |
            output/*.o
            output/*.tar
            model_weights/Qwen3-4B-compiled/mlc-chat-config.json
            compile_log.txt
            gen_config_log.txt
          retention-days: 30
          if-no-files-found: warn
