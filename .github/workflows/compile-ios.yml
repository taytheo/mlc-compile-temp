name: Compile MLC-LLM GPU-only (iPhone) - lib-only

on:
  workflow_dispatch:
    inputs:
      system_lib_prefix:
        description: 'Name prefix for the generated system library (default: qwen3_q4f16_1)'
        required: false
        default: 'qwen3_q4f16_1'
      model_repo:
        description: 'Local folder or HF repo path to use as model_weights (default: model_weights/Qwen3-4B-q4f16_1-MLC)'
        required: false
        default: 'model_weights/Qwen3-4B-q4f16_1-MLC'
      force_convert:
        description: 'Force running mlc_llm convert_weight even if params_shard_*.bin already exists in the model repo (true/false)'
        required: false
        default: 'false'
      require_shards:
        description: 'If true, require params_shard_*.bin present in model_weights (default: false)'
        required: false
        default: 'false'
      always_download:
        description: 'Always download the public HF snapshot rather than relying on a local path (true/false)'
        required: false
        default: 'true'

jobs:
  compile-ios-gpu-libonly:
    runs-on: macos-14
    timeout-minutes: 240

    defaults:
      run:
        shell: bash -el {0}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: "Debug: list ios/scripts after checkout"
        run: |
          echo "Workspace root: $(pwd)"
          echo "Listing ios/scripts (if present):"
          ls -la ios/scripts || true
          echo "Git status:" && git status --porcelain || true

      - name: Setup Conda
        uses: conda-incubator/setup-miniconda@v3
        with:
          auto-update-conda: true
          python-version: "3.11"
          activate-environment: mlc

      - name: Install MLC-LLM Python package
        run: |
          pip install --pre -U -f https://mlc.ai/wheels mlc-llm-nightly-cpu mlc-ai-nightly-cpu
          pip install huggingface_hub

      - name: Patch MLC-LLM bool type bug
        run: |
          echo "ðŸ”§ Applying MLC-LLM Bool íƒ€ìž… ë²„ê·¸ íŒ¨ì¹˜ (GitHub Issue #3389)"
          python3 .github/scripts/patch_mlc_bool_bug.py || true

      - name: Prepare model weights
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          HUGGINGFACE_HUB_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          mkdir -p ./output
          # Follow CPU workflow: download snapshot and update config within the model_weights default dir
          mkdir -p model_weights
          python -c "from huggingface_hub import snapshot_download; snapshot_download(repo_id='mlc-ai/Qwen3-4B-q4f16_1-MLC', local_dir='./model_weights/Qwen3-4B-q4f16_1-MLC')"
          cp ./model_weights/Qwen3-4B-q4f16_1-MLC/mlc-chat-config.json ./model_weights/Qwen3-4B-q4f16_1-MLC/mlc-chat-config.json.bak || true
          python3 .github/scripts/update_mlc_config.py || true
          MODEL_DIR="./model_weights/Qwen3-4B-q4f16_1-MLC"
          # Backup and update config similar to CPU-only workflow
          if [ -f "$MODEL_DIR/mlc-chat-config.json" ]; then
            cp "$MODEL_DIR/mlc-chat-config.json" "$MODEL_DIR/mlc-chat-config.json.bak" || true
            python3 .github/scripts/update_mlc_config.py || true
            # Apply GPU-specific guidance for Metal target
            python3 .github/scripts/set_gpu_shard_config.py "$MODEL_DIR/mlc-chat-config.json" || true
          fi
          echo "Model folder contents:"
          ls -la "$MODEL_DIR" | sed -n '1,200p'

          # If no params_shard_* present, attempt to convert downloaded HF weights to MLC format
          shards=$(find "$MODEL_DIR" -type f -name "params_shard_*.bin" | wc -l || true)
            if [[ "$shards" -eq 0 || "${{ github.event.inputs.force_convert }}" == "true" ]]; then
            echo "No params_shard_* found or force_convert requested; attempting conversion with mlc_llm convert_weight (this may be slow)"
            mlc_llm convert_weight "$MODEL_DIR" \
              --quantization q4f16_1 -o "$MODEL_DIR" || true
            mlc_llm gen_config "$MODEL_DIR" --quantization q4f16_1 -o "$MODEL_DIR" || true
            echo "=== Post-conversion listing ==="
            find "$MODEL_DIR" -maxdepth 4 -type f -name "params_shard_*" | sed -n '1,200p'
          fi

      - name: Validate shards exist (optional)
        run: |
          if [[ "${{ github.event.inputs.require_shards }}" == "true" ]]; then
            # Portable check for shard files using ls; avoids find compatibility issues
            if ! ls "$MODEL_DIR"/params_shard_*.bin >/dev/null 2>&1; then
              echo "ERROR: shards not found under '$MODEL_DIR'" && exit 1
            fi
          else
            echo "require_shards=false - not requiring params_shard_*.bin"
          fi

      - name: Compile GPU-only system lib (iPhone / Metal)
        run: |
          # Ensure MODEL_DIR is set (shell vars don't persist between steps in GitHub Actions)
          MODEL_DIR="./model_weights/Qwen3-4B-q4f16_1-MLC"
          CONFIG_PATH="$MODEL_DIR/mlc-chat-config.json"
          echo "Compiling with MODEL_DIR='$MODEL_DIR'"
          # Check model dir first
          if [ ! -d "$MODEL_DIR" ]; then
            echo "ERROR: Model directory '$MODEL_DIR' not found or not a directory" && exit 1
          fi
          if [ ! -f "$CONFIG_PATH" ]; then
            echo "ERROR: mlc-chat-config.json not found at $CONFIG_PATH"
            echo "Model dir content:"
            ls -la "$MODEL_DIR" || true
            exit 1
          fi
          echo "--- mlc-chat-config.json (post-update) ---"
          jq . "$CONFIG_PATH" || cat "$CONFIG_PATH" || true
          SYSTEM_LIB_PREFIX="${{ github.event.inputs.system_lib_prefix }}"
          OVERRIDES="context_window_size=1024;prefill_chunk_size=32;max_batch_size=1"
          echo "CONFIG: $CONFIG_PATH"
          echo "OUT: ./output/${SYSTEM_LIB_PREFIX}-iphone-libonly.tar"
          python -m mlc_llm compile \
            "$CONFIG_PATH" \
            --device iphone \
            --system-lib-prefix "$SYSTEM_LIB_PREFIX" \
            --overrides "$OVERRIDES" \
            --output ./output/${SYSTEM_LIB_PREFIX}-iphone-libonly.tar \
            2>&1 | tee compile_iphone_libonly_log.txt

      - name: List compiled tar contents
        if: success()
        run: |
          echo "=== TAR contents ==="
          tar -tvf ./output/*.tar | sed -n '1,200p' || true

      - name: Check presence of lib files in tar
        run: |
          OUT_TAR=$(ls ./output/*.tar | head -n 1)
          echo "Checking tar: $OUT_TAR"
          tar -tf "$OUT_TAR" | grep -E 'lib0.o|devc.o' || (echo "WARNING: lib0.o/devc.o not found in tar" && false)

      - name: Extract and inspect devc.o for Metal strings
        if: success()
        run: |
          OUT_TAR=$(ls ./output/*.tar | head -n 1)
          TMPDIR=$(mktemp -d)
          tar -xvf "$OUT_TAR" -C "$TMPDIR"
          if [ -f "$TMPDIR/devc.o" ]; then
            echo "devc.o exists: size=$(stat -f%z $TMPDIR/devc.o)"
            if strings "$TMPDIR/devc.o" | egrep -i 'metal|metallib|MTLDevice|NT_matmul'; then
              echo "Found Metal related strings in devc.o"
            else
              echo "No explicit Metal strings found in devc.o (may still contain compiled kernels)"
            fi
          fi
          rm -rf "$TMPDIR"

      - name: Integrate compiled lib into iOS Runner and build
        if: success()
        run: |
          # Prefer running the integration script via bash to avoid executable-permission issues
          if [ -f "ios/scripts/integrate_compiled_model.sh" ]; then
            echo "Running integration script..."
            EXTRACT_FOR_RUNNER=1 SKIP_BUILD=0 RUN_XCODEBUILD=1 bash ios/scripts/integrate_compiled_model.sh $(pwd)/output || (echo "Integration script failed" && exit 1)
          else
            echo "WARN: ios/scripts/integrate_compiled_model.sh not found in repo workspace. Falling back to inline extraction to populate Runner model dir."
            # Fallback: extract the first tar in output into Runner model dir so downstream checks can validate
            OUT_TAR=$(ls ./output/*.tar | head -n 1 || true)
            if [ -z "$OUT_TAR" ]; then
              echo "ERROR: No compiled tar found in ./output to extract for Runner integration" && exit 1
            fi
            RUNNER_MODEL_DIR="$(pwd)/ios/Runner/qwen3_q4f16_1"
            rm -rf "$RUNNER_MODEL_DIR"
            mkdir -p "$RUNNER_MODEL_DIR"
            echo "Extracting $OUT_TAR into $RUNNER_MODEL_DIR"
            tar -xvf "$OUT_TAR" -C "$RUNNER_MODEL_DIR" || (echo "ERROR: Failed to extract $OUT_TAR" && exit 1)
            # If shards exist in the repo model folder, copy them into the Runner model dir so runtime can mmap them
            if ls ./model_weights/Qwen3-4B-q4f16_1-MLC/params_shard_*.bin >/dev/null 2>&1; then
              echo "Copying params_shard_*.bin from model_weights into Runner model dir"
              cp -a ./model_weights/Qwen3-4B-q4f16_1-MLC/params_shard_*.bin "$RUNNER_MODEL_DIR" || true
            fi
            echo "Fallback extraction complete. Listing contents:" && ls -la "$RUNNER_MODEL_DIR" || true
          fi

      - name: Verify Runner extraction and presence of libs
        if: success()
        run: |
          RUNNER_MODEL_DIR="ios/Runner/qwen3_q4f16_1"
          if [ ! -d "$RUNNER_MODEL_DIR" ]; then
            echo "ERROR: Runner model dir not found: $RUNNER_MODEL_DIR" && exit 1
          fi
          echo "Listing Runner model dir:"
          ls -la "$RUNNER_MODEL_DIR" || true
          if ! find "$RUNNER_MODEL_DIR" -maxdepth 1 -type f -iname '*devc*.o' -print -quit | grep -q .; then
            echo "ERROR: devc.o not found in Runner model dir" && exit 1
          fi
          if ! find "$RUNNER_MODEL_DIR" -maxdepth 1 -type f -iname '*lib0*.o' -print -quit | grep -q .; then
            echo "ERROR: lib0.o not found in Runner model dir" && exit 1
          fi

      - name: Inspect extracted libs for GPU indicators and embedded shards
        if: success()
        run: |
          RUNNER_MODEL_DIR="ios/Runner/qwen3_q4f16_1"
          echo "Scanning for lib files in $RUNNER_MODEL_DIR"
          for f in $(find "$RUNNER_MODEL_DIR" -maxdepth 1 -type f -iname '*devc*.o' -o -iname '*lib0*.o' -print 2>/dev/null || true); do
            echo "--- Inspecting: $f ---"
            echo "Size: $(stat -f%z "$f") bytes"
            echo "Searching for shard references (params_shard|embed_tokens)"
            strings "$f" | egrep -i 'params_shard|embed_tokens|model.embed_tokens' || true
            echo "Searching for GPU/Metal indicators"
            strings "$f" | egrep -i 'metal|metallib|MTLDevice|MPSGraph|MTLCreateSystemDefaultDevice' || true
            if command -v nm >/dev/null 2>&1; then
              nm -A "$f" 2>/dev/null | egrep -i 'MTL|metal|MPS|cuda|cl' || true
            fi
          done
          echo "Check if shard files exist in Runner dir"
          ls -la "$RUNNER_MODEL_DIR"/params_shard_*.bin || echo "No params_shard_*.bin in Runner dir"

      - name: Upload compiled artifacts and logs
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: qwen3-4b-ios-compiled-gpu-libonly
          path: |
            output/*.tar
            output/*.o
            output/*.json
            compile_iphone_libonly_log.txt
            compile_iphone_log.txt
          retention-days: 30
