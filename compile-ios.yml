name: Compile MLC-LLM for iOS

on:
  workflow_dispatch:
    inputs:
      prefill_chunk_size:
        description: 'Prefill chunk size (default: 128)'
        required: false
        default: '128'
      context_window_size:
        description: 'Context window size (default: 4096)'
        required: false
        default: '4096'name: Compile MLC-LLM for iOSname: Compile MLC-LLM for iOS

on:
  workflow_dispatch:

jobs:
  compile-ios:
    runs-on: macos-14
    timeout-minutes: 90
    
    steps:
    - name: Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        
    - name: Install Rust
      uses: dtolnay/rust-action@stable
      
    - name: Clone and Build MLC-LLM
      run: |
        git clone --recursive https://github.com/mlc-ai/mlc-llm.git
        cd mlc-llm
        mkdir -p build && cd build
        python ../cmake/gen_cmake_config.py
        cmake .. -DCMAKE_BUILD_TYPE=Release
        make -j$(sysctl -n hw.ncpu)
        
    - name: Download Model
      run: |
        pip install huggingface_hub
        huggingface-cli download mlc-ai/Qwen3-4B-q4f16_1-MLC --local-dir ./model
        
    - name: Compile for iOS
      run: |
        cd mlc-llm
        export PYTHONPATH=$(pwd)/python:$PYTHONPATH
        
        python -m mlc_llm gen_config ../model \
          --quantization q4f16_1 \
          --prefill-chunk-size 128 \
          --context-window-size 4096 \
          --max-batch-size 1 \
          --conv-template qwen2 \
          --output ../config
        
        python -m mlc_llm compile ../config/mlc-chat-config.json \
          --device iphone \
          --output ../output.tar
        
        cd .. && tar -xvf output.tar
        ls -la *.o
        
    - name: Upload
      uses: actions/upload-artifact@v4
      with:
        name: ios-libs
        path: "*.o"

on:
  workflow_dispatch:

jobs:
  compile-ios:
    runs-on: macos-14
    timeout-minutes: 90
    
    steps:
    - name: Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        
    - name: Install Rust
      uses: dtolnay/rust-action@stable
      
    - name: Clone and Build MLC-LLM
      run: |
        git clone --recursive https://github.com/mlc-ai/mlc-llm.git
        cd mlc-llm
        mkdir -p build && cd build
        python ../cmake/gen_cmake_config.py
        cmake .. -DCMAKE_BUILD_TYPE=Release
        make -j$(sysctl -n hw.ncpu)
        
    - name: Download Model
      run: |
        pip install huggingface_hub
        huggingface-cli download mlc-ai/Qwen3-4B-q4f16_1-MLC --local-dir ./model
        
    - name: Compile for iOS
      run: |
        cd mlc-llm
        export PYTHONPATH=$(pwd)/python:$PYTHONPATH
        
        python -m mlc_llm gen_config ../model \
          --quantization q4f16_1 \
          --prefill-chunk-size 128 \
          --context-window-size 4096 \
          --max-batch-size 1 \
          --conv-template qwen2 \
          --output ../config
        
        python -m mlc_llm compile ../config/mlc-chat-config.json \
          --device iphone \
          --output ../output.tar
        
        cd .. && tar -xvf output.tar
        ls -la *.o
        
    - name: Upload
      uses: actions/upload-artifact@v4
      with:
        name: ios-libs
        path: "*.o"

jobs:
  compile-ios:
    runs-on: macos-14
    timeout-minutes: 60
    
    steps:
    - name: Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        
    - name: Install Rust (required for tokenizer)
      uses: dtolnay/rust-action@stable
      
    - name: Clone MLC-LLM from source
      run: |
        git clone --recursive https://github.com/mlc-ai/mlc-llm.git
        cd mlc-llm
        git submodule update --init --recursive
        
    - name: Build MLC-LLM from source
      run: |
        cd mlc-llm
        mkdir -p build && cd build
        python ../cmake/gen_cmake_config.py
        cmake .. -DCMAKE_BUILD_TYPE=Release
        make -j$(sysctl -n hw.ncpu)
        
    - name: Download Qwen3-4B MLC weights
      run: |
        pip install huggingface_hub
        huggingface-cli download mlc-ai/Qwen3-4B-q4f16_1-MLC --local-dir ./Qwen3-4B-MLC
        ls -la ./Qwen3-4B-MLC/
        cat ./Qwen3-4B-MLC/mlc-chat-config.json
        
    - name: Generate config with small buffers
      run: |
        cd mlc-llm
        export MLC_LLM_SOURCE_DIR=$(pwd)
        export PYTHONPATH=$MLC_LLM_SOURCE_DIR/python:$PYTHONPATH
        
        python -m mlc_llm gen_config ../Qwen3-4B-MLC \
          --quantization q4f16_1 \
          --prefill-chunk-size ${{ github.event.inputs.prefill_chunk_size || '128' }} \
          --context-window-size ${{ github.event.inputs.context_window_size || '4096' }} \
          --max-batch-size 1 \
          --conv-template qwen2 \
          --output ../mlc_config
        
        cat ../mlc_config/mlc-chat-config.json
        
    - name: Compile for iOS (iPhone)
      run: |
        cd mlc-llm
        export MLC_LLM_SOURCE_DIR=$(pwd)
        export PYTHONPATH=$MLC_LLM_SOURCE_DIR/python:$PYTHONPATH
        
        mkdir -p ../ios_compiled
        python -m mlc_llm compile ../mlc_config/mlc-chat-config.json \
          --device iphone \
          --output ../ios_compiled/model-iphone.tar
        
        ls -la ../ios_compiled/
        
    - name: Extract tar and show results
      run: |
        cd ./ios_compiled
        tar -xvf model-iphone.tar
        ls -la
        
    - name: Upload compiled artifacts
      uses: actions/upload-artifact@v4
      with:
        name: ios-compiled-libs
        path: |
          ./ios_compiled/lib0.o
          ./ios_compiled/devc.o
          ./mlc_config/mlc-chat-config.json
        retention-days: 30
